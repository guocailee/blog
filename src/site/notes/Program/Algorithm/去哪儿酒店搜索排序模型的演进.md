---
{"dg-publish":true,"permalink":"/Program/Algorithm/去哪儿酒店搜索排序模型的演进/","noteIcon":"","created":"2025-02-17T17:06:48.130+08:00"}
---



Original 杨旭 Qunar技术沙龙 _2025年02月17日 17:02_ _北京_


****作者介绍：****

**杨旭**，2019年加入去哪儿旅行，目前在算法团队担任搜索推荐算法工程师，主要负责国内酒店搜索排序相关工作。通过分析理解数据，基于不同的场景和任务进行模型迭代升级，提升国内酒店的转化率和收益。

  

# **一、背景**

在用户在线浏览酒店时，旅行平台需要解决一个重要问题：如何更好地为用户挑选适合的酒店，并降低用户选择的费力度。而为用户挑选符合需求的酒店，需要千人千面的模型排序。在去哪儿（Qunar）APP中，触发个性化排序的场景主要是欢迎度排序（见图1）。

![Image](https://mmbiz.qpic.cn/sz_mmbiz_png/YE1dmj1Pw7l9mMWn4GAsIicdh12SlvRjoTNsyUurtr0VlxFe6l9uZDpszicibBZSn0NhB9YydN4XQ4jrEn8jrz0SA/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

图1 Qunar酒店搜索产品形态

# **二、****Qunar酒店搜索排序架构**

Qunar酒店搜索推荐系统的总体流程可以分成四块，主要是召回、粗排、精排、重排。其中精排主要会根据用户的搜索关键词和其他相关信息，筛选出与用户需求最相符合的酒店，确保在搜索结果中，用户能够看到那些与其需求最相关的酒店。而Qunar酒店长期优化的业务目标是s2o，即下单用户数/搜索用户数。

![Image](https://mmbiz.qpic.cn/sz_mmbiz_png/YE1dmj1Pw7l9mMWn4GAsIicdh12SlvRjohYCV8bJU6RehHrQiaReybVJkOga9NMJhllbmpkEfYibgSqpemuREqzcw/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

图2 Qunar搜索架构

**三、****Qunar酒店搜索精排排序的发展历程**

第一阶段升级机器学习模型，酒店搜索业务准备使用机器学习模型替换人工规则排序。为了能快速上线验证模型效果，并考虑到酒店业务天生自带大量连续特征，如酒店价格、酒店距离等，我们选择了对连续特征比较友好的树模型LambdaMart模型。

第二阶段升级深度模型，LambdaMart排序模型常用的迭代优化手段，如添加特征、样本调整等几乎已经无法带来增量收益，因此我们准备升级成比树模型天花板更高的深度模型架构LambdaDNN。

第三阶段升级多目标模型，LambdaDNN排序模型主要还是聚焦单目标建模（CTCVR），而多目标建模更好的考虑了排序全空间的曝光样本，综合考虑了下单前的用户点击行为，降低样本偏差问题，我们借鉴了Google的MMOE模型，同时学习CTR目标任务和CTCVR目标任务。

第四阶段升级多场景多目标模型，酒店业务搜索场景分为同城空搜、异地空搜等，每个场景单独一个模型，使得维护成本很高，并且用户出行时，会在多个场景（同城搜索、异地搜索）下搜索找到符合自己期望的酒店。若将多个场景分别单独训练模型，会使得用户连贯的搜索行为割裂，学习不到用户在不同场景下的差异和共性。因此，我们提出将信息表征拆分，融合多场景样本的多场景多目标模型。

下面具体阐述我们在Qunar酒店搜索排序模型的演进。

**四、****Qunar酒店搜索精排排序算法的迭代**

排序学习（Learning to Rank）是一个监督学习过程，给定一个query，搜索引擎会召回一系列相关的item，然后对这些召回的item进行排序，最后将Top N的item输出。而排序问题就是使用一个模型 f(q,d)来对该query下的item进行排序，分为PointWise，PairWise，ListWise三种排序学习方式。

PointWise：输入空间中样本是单个 item（和对应 query）构成的特征向量，输出空间中样本是单个 item（和对应 query）的相关度，是将所有用户的样本空间的样本同等对待。

PairWise：输入空间中样本是（同一 query 对应的）两个item构成的两个特征向量，输出空间中样本对的偏序关系，此方法学习了同一个query下的两个样本对比偏好。

ListWise：输入空间中样本是（同一 query 对应的）所有item构成的多个特征向量列表，输出空间是同一个query下的最优排序列表，是pairwise和lambda梯度的结合，如LambdaMart算法，对整个列表建模，学习一个最优排序列表。

![Image](https://mmbiz.qpic.cn/sz_mmbiz_png/YE1dmj1Pw7l9mMWn4GAsIicdh12SlvRjoJhUF9c3W6jRACrtk3ZL3C79BkjSXNYibibYBBOxJ3gxPKR9n6cFrCCfQ/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

模型的预测目标与业务指标之间存在一定的差距，Pointwise注重单个物品的点击率，对所有请求下的物品同等对待，与搜索业务指标存在较大的Gap，而搜索业务更关注在页面头部的搜索结果的优劣。

因此，初期阶段我们选择了更适合搜索排序的Listwise方式学习模型，即LambdaMart树模型作为base模型，同时树模型不需要做大量的特征处理，可以快速上线验证效果、拿到收益。

### ****1. 由LambdaMart模型升级到LambdaDNN模型****

将排序模型从LambdaMart升级到LambdaDNN模型主要考虑到以下几点：

- 旅游具有强烈的节假日周期属性，需要长时间窗的大规模数据学习。而树模型容量有限，随着数据规模的增加，很难很好的表达数据内部隐藏的知识。LambdaDNN能够实现更复杂的模型，且具备强大的表征能力，有更高的天花板。
    
- 基于深度学习的模型，具有更好的泛化能力，和处理高维稀疏数据的能力，此外应用深度学习模型后可以更好的应用新的研究成果，比如后面介绍的多目标排序。
    

树模型和深度模型的主要区别见表1。

表1

| **特征工程** | **在线学习**                             | **稀疏特征**                           |                      |
| -------- | ------------------------------------ | ---------------------------------- | -------------------- |
| **树模型**  | 优化后期，增大数据量、特征工程收益变小                  | 不适合在线学习，酒店用户在节假日行为有较大不同，这时需要快速更新模型 | 对高维的稀疏向量不友好，如ID类特征   |
| **深度模型** | 网络结构和参数可以调整的空间更大，表达能力也更强，可以优化提升的空间更大 | 可以进行在线学习，多目标学习                     | 容量更大，可以处理高维稀疏特征，如ID类 |

### **2. LambdaDNN模型实践**

为了验证深度模型的有效性，我们控制了loss的学习方式，统一为listwise方式，唯一变量只是模型的结构。而LambdaDNN模型是将神经网络DNN与LamdaRank [2] 定义的NDCG排序指标梯度相结合，演进出了LambdaDNN，是一种listwise的学习方式。因此我们尝试将LambdaDNN模型应用在了Qunar搜索推荐下的精排阶段，

模型学习目标定义为曝光转化率（ctcvr）。LambdaDNN的搭建主要包括了框架选型、样本构造、特征工程、模型离线训练及线上化，其中样本与特征决定了模型效果的上限。接下来分别介绍下这几个部分：

#### **2.1 框架选型**

TensorFlow Ranking (TFR) 是 TensorFlow 官方开发的 LTR 框架，旨在基于 TensorFlow 开发和整合 LTR 相关的技术，使开发人员可以更加方便的进行 LTR 算法的开发。TFR 使用了 Estimator API，提供了排序任务常见的损失函数和指标计算实现，比如 listwise Loss 和 NDCG指标。

根据训练流程，模块结构可以分成特征输入、特征转换、模型打分和损失计算等模块。这样的模块划分可以提高后续快速迭代的便利性和灵活性，而不用关注于各种实施上的细节。

![Image](https://mmbiz.qpic.cn/sz_mmbiz_png/YE1dmj1Pw7l9mMWn4GAsIicdh12SlvRjoeibIj1gIlW5gicfaG7kph1UOXM935DfdAlCbSZ1cbpxqbGLgYQ0GoU0g/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

图3 TFRanking框架

如上图3所示，model_fn 参数内需要自己设计和开发的算法模型模块。在这个 model_fn 中，需要自行设计模型结构 (Scoring Function)，然后用模型计算的 logit 和 label 来计算 Loss 和 Metrics，最后利用 Optimizer 来进行模型的优化。图3中的下方部分为使用 TFR 服务的整个流程。

为了配合 TFR 框架中的 LTR 相关的 Loss 和 Metrics 来实现 LTR 的训练，训练数据需要以 listwise 的形式组织。即LTR 模型与一次只对一个item进行分类的标准分类模型不同，它会将整个items列表接收输入，并学习排序，充分提升整个list列表的效用，如图4所示。

![Image](https://mmbiz.qpic.cn/sz_mmbiz_png/YE1dmj1Pw7l9mMWn4GAsIicdh12SlvRjop33IKic4oI8WaibqVeb7icAZMItG7jzFC0ibTg0iaibfCONccpabmEotzR2g/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

图4 listwise的学习方式

#### **2.2 模型结构**

我们使用的模型结构，借鉴了Airbnb的深度学习[3]模型演进的经验，模型探索的原则是从简单到复杂，逐步积累经验，针对特征数量不多的情况下，使用非常深的网络，会导致过拟合。因此，如图5所示，采用了简单2层隐藏层的金字塔网络结构。

对一个query下的样本计算Lambda Loss，优化网络参数。其中，模型调优参数，batch size为1024，加入dropout和Batch Normalization（BN），梯度优化器是Adam，学习率为0.01。输入特征仅为77维，隐藏层神经元数为[128，86]。

![Image](https://mmbiz.qpic.cn/sz_mmbiz_png/YE1dmj1Pw7l9mMWn4GAsIicdh12SlvRjoS8I1mmR2qMlWoLJUsiag3XIQLTJlj2jj20Fr1iazbvRFuib9W4ibQGQnAA/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

图5 模型结构

#### **2.3 样本构造**

为了训练listwise模型，需要构造样本来表示用户的查询query和item之间的关系。图6(左图)显示了一个典型的用户搜索旅程的简化示例，其中客户在多天内进行多次query搜索，并点击多个搜索结果以查看其详细页面，最终在第M日query#3下的结果列表中用户点击了酒店（hotel-b）和下单了酒店（hotel-d），整个会话以用户下单酒店成功结束。

![Image](https://mmbiz.qpic.cn/sz_mmbiz_png/YE1dmj1Pw7l9mMWn4GAsIicdh12SlvRjoX3LKD5BEQvdicaliciaApjLO2RyGFYnIx0pZBnNBjtxYLutUrdnJUwWOw/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

图6 用户搜索行为示例

在我们的业务场景下，线上业务优化目标为下单转化率，对应离线建模目标为曝光转化率（ctcvr），即从search到order的转化，训练的目标是从曝光到下单的转化。

- list列表选择：
  - 在以Listwise方式学习时，我们只使用含有成功下单的搜索列表（Day M的query#3）为List训练样本，Day1和Day2下的无下单列表样本将丢弃，标签见图6（右图）； 
  - 原因是若将只有点击标签的list加入训练，在计算NDCG时，不管点击标签的值是0.01还是1，ndcg的值都是一样，此时计算LambdaLoss时，模型会更倾向于只有点击的list，重点优化了ctr。

- 正样本构造：
 - 下单酒店标签1；
   - 点击酒店标签0.01，标签值表示样本和query的相关度大小，可根据实验效果调整（点击和下单相关度比值我们是数据统计得来）。我们认为用户点击过的酒店是具有一定的喜好，不能简单的设置标签为0。

- 负样本构造：
  - hard negative sample：曝光未下单且未点击的酒店；
  - easy negative sample：在同一个list列表中，采样list列表最底部的n家(<<当次请求曝光酒店数)未曝光的酒店，标签为0。由于线上精排排序家数较多，只选取曝光样本训练，模型对easy负样本学习不好。推荐结果会有部分低质量酒店，需要采样部分低质酒店作为easy negative sample，修正线上线下样本分布偏差，提升模型泛化能力。

- 样本量：模型训练的样本以时间维度切分，30天为训练集，7天作为验证集，7天作为测试集。
    

工程实践：Listwise学习方式的Lambda梯度需要对同Query下的样本进行计算。因此我们需要对样本进行预处理：将同一个查询(Query)的样本聚合在一起，采用ExampleListWithContext编码方式，将这些样本打包进一个TFRecord中。由于每次请求Query召回的item数不一样，对于可变Size的Query样本在拉取数据进行训练时需要注意，TF会自动补齐Mini-Batch内每个样本大小一致。

#### **2.4****特征工程**

特征工程主要包括特征构建、特征分析、特征处理，以及特征选择等：

**特征构建：**

- 用户特征：用户行为特征，如过去1年下单的次数，下单该酒店的次数，用户画像等
- 酒店特征：属性特征等，如价格，档次，星级，点击率，转化率，节假日等
- 交叉特征：用户到酒店的距离，poi到酒店的距离等
- 上下文特征：时间，搜索场景等

**构建原则：**

- 防止特征穿越
- 尽量和业务相关
- 有区分性，尽量使特征能很好的区分出正负样本。
    

**特征选择：**

- 深度模型相对于树模型对特征值的大小更敏感，没有像树模型一样有自动特征选择功能，引入一些冗余特征会增大深度模型的噪声。因此我们基于LambdaMart的特征重要性排序，选取最重要的特征训练LambdaDnn，如图7所示，top49维（总维度是200维）时，测试集合的ndcg@10指标（test_ndcg）和全量特征ndcg@10（origin_test_ndcg）相比持平，且特征在top25维时指标不在增长。考虑到深度模型的参数空间更大，学习能力更强，我们在top49维特征的基础上，基于人工经验又挑选了28维特征，一共77维。
    

![Image](https://mmbiz.qpic.cn/sz_mmbiz_png/YE1dmj1Pw7l9mMWn4GAsIicdh12SlvRjolNPUzn2t1kibroiczGHTWWwiaN3kyHnuU48lSKoQFhZWq6puawEMIwZ3A/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

图7 选择不同top数量的特征训练后的模型效果

**特征分析：**

深度模型对特征大小较为敏感，因此特征处理的好坏直接影响后续模型的表现。

- 长尾分布：例如点击率、点击次数等特征，80%的值分布在靠近0的附近，若直接加入模型训练，由于值差距太小，和其他特征相比没有区分性，因此需要做一些log变换后为正态分布，更有利于模型收敛。如下表：

![Image](https://mmbiz.qpic.cn/sz_mmbiz_png/YE1dmj1Pw7l9mMWn4GAsIicdh12SlvRjoTokrucVyvwbQow5qXqqyvdmYouY1TOnJQ0GLDhaSHbASOGYMu4DbUg/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

- 正态分布：价格等取值较大连续特征，使用了最大最小归一化方法，将特征值都转化为0-1之间的数值。
- 缺失值填补：在训练样本中不可避免地有部分连续特征存在缺失值，合理处理缺失值会对最终效果有一定帮助。填补缺失值的方式有：
- 取零值，会导致相应权重无法进行更新，收敛速度减慢。
- 取平均值也略显武断，毕竟不同的特征缺失所表示的含义可能不尽相同。
- 我们希望神经网络也可以通过学习的方式自适应地处理缺失值，而不是人为设置默认值。对较为重要的特征（特征重要度可通过模型的信息增益得分得到），且缺失率较大的，填补值为0，同时对缺失特征学习一个缺失权重，如下公式所示：
    

![Image](https://mmbiz.qpic.cn/sz_mmbiz_png/YE1dmj1Pw7l9mMWn4GAsIicdh12SlvRjoxgxfkvvZdBibBqIyUPmibKDCusicQJIxruTVia3BJ3frgLNqdhZIrQUqhw/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

我们通过上述变换方式，让所有特征范围在0-1之间或者0附近，在输入模型后经过一层bn操作进行正态分布处理。当然还有其他处理方式，具体还要根据自己业务选择合适的处理方式。

#### **2.5 实验评估**

baseline模型即LambdaMart，离线ndcg@10效果如下表，LambdaDnn线上转化率提升0.5%。

| **NDCG@10**    |        |
| -------------- | ------ |
| **LambdaMart** | 0.7310 |
| **LambdaDnn**  | 0.7463 |

### **3. 多目标模型优化**

在类似电商搜索推荐系统中，用户的行为通常按照一种序列化的模式进行，即首先是曝光，然后是点击，最后是转化。因此，CTCVR模型的作用是预估在曝光发生后的转化概率。

#### **3.1 为什么选择多目标建模？**

**单目标方式缺陷：**

1）样本选择偏差问题

- 训练阶段：Listwise模式训练样本是用户最后一次在Day M日query#3下的下单列表，下单前的行为列表都被丢弃。
- 在线推断：query#1、query#2的列表都会经过推理，此时样本是有选择偏差的，离线训练和在线推理样本分布不一致，模型很难学习到真实样本分布信息，导致模型的泛化性能降低；
- 对无下单行为的用户学习效果较差

2）模型分可解释性差

- Listwise模式学习的输出是偏序关系，值范围较大，不是在[0-1]之间，且每一次请求的值范围区间不同，对后续业务重排策略调整难度较大。若归一化到[0-1]后，不像实际ctr一样具有物理含义。

3）数据稀疏，模型泛化能力不足
- 若pointwise模式只使用曝光和下单样本训练CTCVR目标时，下单数据非常稀疏，下单样本的数量远远小于曝光样本。而利用CTR任务的丰富数据可以帮助CTCVR任务克服数据稀疏性问题，提高模型的泛化能力和预测性能
    

**多目标优势：**

1）缓解样本偏差，及稀疏性

- 将曝光点击下单都可以加入到模型中学习

2）可解释性好
- 输出值是概率意义，更好融合后面的重排加权策略；

3）促进作用

- 通过共享一些浅层次的特征，多任务学习可以借助彼此之间的相似性和差异性来促进学习过程
    

4）约束作用

- 当多个任务同时进行反向传播时，由于不同任务具有不同的噪声模式，多目标可以将多个任务的反馈信息结合起来，平均噪声模式，从而得到更一般和稳定的表征，有点像正则化的作用。通过这种方式，相对于单个任务，模型的过拟合风险会降低，泛化能力会提高。
    

#### **3.2 多目标建模选型**

MMOE是谷歌18年提出的模型结构，其思想是所有目标共享多个experts，但是考虑到不同任务之间的差异性，为每一个目标设置一个gate门控网络，用来控制不同目标选择每个expert的信号占比，类似于weighted sum pooling操作。

MMOE（如图8所示）通过共享experts学习到不同任务的联系和差异，提高了每个任务的学习效率和质量，同时通过gates来平衡多个任务对experts信号的选择，不要求目标之间必须是高相关性的，MMOE是业界通用的多目标实现算法。

多目标建模更好的考虑了排序全空间的曝光样本，综合考虑了下单前的用户点击行为，降低样本偏差问题，引入了多个专家、2个目标任务、一个CTR目标任务和一个CTCVR目标任务。

![Image](https://mmbiz.qpic.cn/sz_mmbiz_png/YE1dmj1Pw7l9mMWn4GAsIicdh12SlvRjoTscwnee6QiadkSnFDQEIpjm4sGOdw7XE6fUODricyhCDeicwBJWZRM6uQ/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

图8 MMOE网络结构

#### **3.3 MMOE样本选择**

1）只选取有行为的搜索列表，即该列表是有被点击或被下单的酒店的列表；

- 原因：正负样本比例相差较大，过滤一部分认为无效负样本；其次训练时避免没有正行为用户的影响，在一批数据中如果某个用户对所有展示的物品都没有点击等行为，应当过滤掉该用户的记录（没有正行为用户只提供负例，看不出用户喜好，对模型训练没有帮助）。
    

2）选取每个列表的曝光样本，以及每个列表的最底部未曝光的n家酒店作为easy negative sample，防止排序出一些较差的酒店。

3）同一个请求列表中的酒店被点击多次的，只记录一次点击行为，即一次点击正样本。

#### **3.4 MMOE训练过程中遇到的问题**

1）实际的业务数据中，曝光到转化过于稀疏，具体训练过程中ctcvr的loss明显比ctr的loss小。为了使得2个目标任务的loss的量级一致，并没有采用loss加权处理，而是在样本构造过程中对下单样本进行上采样复制，保持正负样本1:1，基本上可以使得目标loss大小量级一样。

这样在训练shuffle时，不会使得一个正样本在batch内重复出现N次，使得ctcvr任务泛化性更好，同时对ctr任务中的上采样过的点击样本进行降权处理，恢复原先样本分布。

2） gate network输出进入饱和区，反向传播梯度消失：

expert gate输出，是由输入特征经过门网络后softmax得到，在训练的过程中，经过一段迭代次数，门控网络的输入值方差变大，经过softmax后gate network大部分输出是0，在这种情况下，multi expert的优势就没办法发挥出来，

一种解决方式是dropout，依然解决不了部分值偏大的问题；另一种方式对进入softmax之前的得分，进行得分除以一个lambda平滑处理（即，温度系数的调节），缓解部分专家退化现象；这里取lambda为输入特征的维度，也可以参考self-attention。

![Image](https://mmbiz.qpic.cn/sz_mmbiz_png/YE1dmj1Pw7l9mMWn4GAsIicdh12SlvRjoIH5u1P3Tk8G8tDhg1iaxBZsGAwUBZSibb64EbWU5y2qjJlouaOyCTdFQ/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

如下表指数e函数曲线中所示，x的域范围在[-10,10]区间时，softmax的值很容易在x小于-2.5时为0，x大于10时为1。如果将x缩放尺度为1/100，就会缓解退化问题。

![Image](https://mmbiz.qpic.cn/sz_mmbiz_png/YE1dmj1Pw7l9mMWn4GAsIicdh12SlvRjosBoT2micwFwQIFpH2zm98zMamt6lRI0q4z0G0h71soziaVJYz3CibkXHg/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

#### **3.5 实验结果**

线上预测时，我们会加权融合两个目标预测值作为排序分，而融合权重可以通过离线数据拟合得到。

从下表中，我们的MMOE最终的离线指标NDCG@10没有提升，主要的原因是测试集是只能在有下单的请求上预测，而lambda直接学习的ndcg目标，所以ndcg更高。而多目标线上的ctr有明显提升，线上点击率提升2%，转化率持平。

| **LambdaDnn** | **MMOE**  |            |         |         |
| ------------- | --------- | ---------- | ------- | ------- |
| **未采样**       | **下单上采样** | **gate缩放** |         |         |
| **NDCG@10**   | 0.7477    | 0.74048    | 0.74407 | 0.74738 |

### **4. 多场景多目标优化**

#### **4.1 业务背景**

在用户出行想要预定酒店时，搜索酒店列表是一个常见的行为。根据用户所处空间不同、搜索行为不同，分为：异地空搜，同城空搜等场景，并且一个用户会跨不同场景进行搜索。而之前模型建模，每个场景单独训练一个模型，一是树模型容量小等历史原因延续单独建模，二是每个场景下所使用的特征不一样，特征的索引也没有对齐。

单独建模不会受到其他场景下的特征影响，其次也可学到单个场景独有的一些特点。但是带来的问题是不同场景下的共有信息无法相互共享、无法迁移学习，造成了信息孤岛。因为同一个用户会在不同场景下都有搜索行为，将同一个用户行为样本分开建模显然是不合理的，同时对多个模型的维护成本也很高。

因此，升级到了MMOE模型后，我们考虑将几个场景下的样本融合学习一个模型，宗旨是既可以学习到场景间独有信息，也能迁移学习不同场景下的共有信息。

#### **4.2 多场景样本如何进行融合？**

不同场景下用户和item存在重叠，具有一定共性，不同场景下的用户行为，具有一定差异性；不同任务之间具有不同的稀疏性，同时也存在相互影响；如果在建模过程中忽略了多场景和多任务之间的共性和差异性，会影响建模效果，如果多个场景和任务不能很好地进行平衡，会存在场景跷跷板和 任务跷跷板现象。

一开始我们也是调研了目前不同场景下建模的方式，如阿里STAR、HMOE等多场景建模方式，但是效果不佳。原因是STAR、HMOE模型都是对不同场景下的分布差异较大的样本进行建模，会有比较好的效果。例如、淘宝的商品的主搜列表推荐、和主页的猜你喜欢等不同的多个频道的建模，而在去哪儿的酒店场景，其实还都是一个频道，用户的行为分布都是一致的，在目的地确定的前提下，无论是poi搜索、同城搜索，都是想预定目的地下的符合需求的酒店。

因此，我们尝试了直接将多个场景的样本放在一起学习，同时特征一起输入到MMOE中，简单的hard-share效果比STAR、HMOE效果会好。我们将训练完的模型，输出每个场景的专家权重，来分析不同场景下的权重是否分布一样。

![Image](https://mmbiz.qpic.cn/sz_mmbiz_png/YE1dmj1Pw7l9mMWn4GAsIicdh12SlvRjoN9HnMh3V9iau81RwSU3dxy5gSaNaj8H0icAwXliaWwic3nc0vRWJiaUHIog/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

图9 不同场景下样本在专家下的权重占比

从图9来看，不同场景下的专家权重，分布几乎一致，最高的权重是专家2。侧面验证了，在我们的业务下场景间的分布差异没有很大。线上的下单转化相对提升0.56%。

#### **4.3 多场景下特征如何对齐？**

对于酒店业务下的特征，特征主要分为4类：

- 场景无关特征：如酒店价格、用户点击次数、下单次数等
    
- 场景共有特征：如酒店在poi下的转化率、点击率等，此时特征会共用一个特征索引
    
- 场景独有特征：如同城空搜下用户距离酒店的距离，poi场景下poi距离酒店的距离等，此时，特征索引不共用
    
- 场景标识特征：主要就是场景 ID 类特征
    

如上所述，输入部分，将场景的domain信息作为特征和场景共有特征一起拼接输入到感知网络中，抽取场景间共性信息；将场景的domain信息作为特征和场景特有特征一起拼接输入到感知网络中，抽取场景间差异信息；

如果统一作为MMOE的输入直接输入，模型无法很好的学习到不同场景的差异，若人为先验的分为上述几类特征，拉平场景特征之间的差异。可以使得模型在一个稳定的样本分布下学习，增强模型对用户跨域行为的底层感知能力。

![Image](https://mmbiz.qpic.cn/sz_mmbiz_png/YE1dmj1Pw7l9mMWn4GAsIicdh12SlvRjoFkGNE8T1nK8dugMOv5iay6WGAx50ovsQkFJxUYWYTf2KBX7ia4fGIPHg/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

图10 多场景多目标网络结构

#### **4.4 实验评估**

- 在v2阶段多场景样本合并时，ndcg@10指标提升不大，多个场景下的样本融合后，网络的参数量不能很好的表达出场景间的特性。
    
- 因此，将网络专家数扩大到8个，希望每个专家能充分学习到场景间差异，离线指标ndcg@10相对v1提升0.19%，上线后，s2o指标提升0.46%，另外，我们做了其他的专家数量的实验，发现增加9个以后，ndcg指标没有什么变化。
    
- 为了更好的对齐场景的特征差异，我们对输入特征分类建模输入MMOE（v4）。此时，离线指标ndcg@10相对提升0.22%，上线后，s2o指标提升0.51%。
    

|                |            |             |             |
| -------------- | ---------- | ----------- | ----------- |
| **模型**         | **特征处理方式** | **专家个数**    | **NDCG@10** |
| **v1.样本未融合**   | \|4        | 0.78416     |             |
| **v2.多场景样本合并** | \|4        | 0.78449     |             |
| **v3.多场景样本合并** | \|8        | **0.78566** |             |
| **v4.全场景融合**   | 特征分类建模输入   | 8           | **0.78745** |

  

### ****5. 特征选择****

#### **5.1 为什么需要做特征选择？**

随着Qunar酒店排序模型业务需求的迭代，越来越多的特征被引入模型中，导致出现如下问题：

- 冗余特征增多
  - 有些特征可能与当下的问题无关。这意味着它们与模型要解决的任务完全无关，丢弃不相关的特征可以防止模型得到无关特征上可能携带的虚假相关性，从而避免过拟合。
- 维度灾难
  - 特征选择技术在具有许多特征但训练示例很少的场景中尤为重要。这种情况受到所谓的维度灾难的影响：在高维空间中，每个训练示例都与其他所有示例相距甚远，因此模型无法学习任何有用的模式。
- 训练时间长
  - 特征越多，训练时间就越长。这种权衡的具体细节取决于所使用的特定学习算法，但在需要实时进行再训练的情况下，可能需要限制在几个最佳特征中进行。
- 部署工作成本高
  - 特征越多，机器学习系统在生产中就越复杂。这会带来多种风险，包括但不限于高维护工作量、纠纷、未申报的使用者或纠正级联。
- 可解释性差
  - 由于特征太多，我们失去了模型的可解释性。虽然对模型结果的解释并不总是主要的建模目标，但通常很重要，在某些受监管的领域，甚至可能是法律要求。
    

#### **5.2 传统特征选择方法**

- 无监督的特征选择方法
- 包装器特征选择方法
- 过滤器特征选择方法
- Boruta（布尔塔）方法
    

上述传统方法更适合数量小，训练时间短，模型简单的场景。而我们深度模型采用了基于dropout 的特征选择，借鉴了论文Dropout Feature Ranking for Deep Learning Models 的工作。

#### **5.3 使用变分dropout来做特征的排序**

![Image](https://mmbiz.qpic.cn/sz_mmbiz_png/YE1dmj1Pw7l9mMWn4GAsIicdh12SlvRjoBM2avl4Z2xv7POIe2Ndt6N1Opc5ibg7baVjT9DuQqMtia0Nv3thRbVTQ/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

图11 dropout的训练前后的丢弃概率示意图

基于两阶段，第一阶段需要先训练一个pretrained Model 这样先学习模型的参数，第二阶段固定模型参数不做梯度更新，对输入的特征增加一个dropout丢弃变量（可导）与输入特征元素相乘，这个阶段的主要目的是优化该dropout丢弃概率。

如图11所示，论文提出了Dropout Feature Ranking方法，在训练完后，可以获取到每个特征的重要度。

本质的思想是将不可导的离散变量dropout，采用Concrete relaxation操作，对符合伯努利分布的离散变量近似估计为一个连续可导变量。松弛为连续性的噪声扰动过程，使其可以进行梯度更新。并对1-dropout_rate添加正则，使其在训练中尽可能最小化。图12 中的p就是特征的丢弃概率。

![Image](https://mmbiz.qpic.cn/sz_mmbiz_png/YE1dmj1Pw7l9mMWn4GAsIicdh12SlvRjoPy9HXUyuvVdft34AGcHlRicTLKKEG96nG32IlYWTGQib4ohiaTVmkKJBg/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)


这种方案的优点：

- 通用性高：可以应用于任何深度学习模型
- 简单方便：在训练好的模型只进行一次dropout参数训练即可得出特征重要性排序，无需进行多次实验来剔除特征
- 效果可靠：该方法在实际业务应用中展现出了出色的特征筛选效果。
    

#### 实验效果：

1、为了验证无效特征会影响模型的效果，我们在模型的原特征基础上增加了10个随机生成的噪声生成噪声特征（在某些特征上添加均匀分布噪声、高斯分布噪声等）

2、加上DFR层后，删减了14维特征后，模型效果不但没有下降，反而有微弱的提升。删除特征重新训练模型，线上转化率提升0.2%。

| **ndcg@10**                 | **相对降低** |         |     |
| --------------------------- | -------- | ------- | --- |
| **v1：基线模型（特征数310）**         | 0.74956  |         |     |
| **v2：基线模型+增加10个噪声（特征数320）** | 0.74270  | -0.915% |     |
| **v3：基线模型+DFR（特征数296）**     | 0.75038  | 0.109%  |     |

3、使用DFR算法后，特征重要性如下：

- 基本上是实时特征更重要
- 我们将低于对照特征（高斯噪声）重要度分的特征删除，基本上是一些冗余特征。
    

| **特征名** | **特征重要度分（1-p）** | **含义**                         |
| ------- | --------------- | ------------------------------ |
| f_10    | 0.9977435       | 实时类特征                          |
| f_16    | 0.9972702       |                                |
| f_1     | 0.9955838       |                                |
| f_20    | 0.9914903       | 用户和酒店交叉类特征                     |
| f_31    | 0.8450232       |                                |
| f_40    | 0.7709408       |                                |
| ....... | .......         |                                |
| f_noise | 0.2733287       | 随机生成高斯分布的对照特征                  |
| f_150   | 0.1862088       | 酒店统计类特征（前面已提取过相关特征，基本上是一些冗余特征） |
| ....... | .......         |                                |
| f_130   | 0.1356599       |                                |
| f_0     | 0.0001341       | 值全为0的对照特征                      |

## **五、阶段总结和未来规划**

本文主要介绍Qunar在酒店搜索精排模型上的演进实践，从实验效果来看，证明了深度模型在酒店搜索排序的有效性，以及合理引入多场景特征间的差异建模可以让模型更好的理解数据。

对于接下来的深度模型优化：借鉴listwise的建模方式，将pointwise loss和listwise loss融合，既可以学习排序，又可以学习判别分类。

  

[1]Chris J.C. Burges. 2010. From RankNet to LambdaRank to LambdaMART: An Overview. Technical Report. https://www.microsoft.com/en-us/research/publication/from-ranknet-to-lambdarank-to-lambdamart-an-overview/

[2] Rama Kumar Pasumarthi, Sebastian Bruch, Xuanhui Wang, Cheng Li, Michael Bendersky, Marc Najork, Jan Pfeifer, Nadav Golbandi, Rohan Anil, Stephan Wolf. _TF-Ranking: Scalable TensorFlow Library for Learning-to-Rank._ KDD 2019.

[3] Haldar M, Abdool M, Ramanathan P, et al. Applying deep learning to airbnb search[C]//Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 2019: 1927-1935.