---
{"dg-publish":true,"permalink":"/XLife/Other/计算神经科学能否成为未来人工智能的发展方向/","noteIcon":"","created":"2024-05-22T16:17:54.168+08:00"}
---






刚刚过去的一个周末，在twitter上的神经科学圈发酵了一起不大不小的争论，引得领域内好几个著名学者，包括Yann Lecun的参与。 最初争论的是神经科学是否推动了人工智能，后来就更多变成了未来的人工智能是否需要神经科学。

吃完瓜后，感觉里边还是有一些很不错的观点，在此小记复盘一下。其中的翻译并非按照原文逐词翻译，只是换成我个人语言理解而已。抛砖引玉，欢迎大家有更多的观点。

争论的起点
-----

10月15号时候，神经科学领域和人工智能领域一群大佬，如Terry Sejnowski, Yoshua Bengio， Yann LeCun，, Eero Simoncelli, James DiCarlo, Alex Pouget 以及今天争论的主角Konrad Kording， 在arXiv上发表了一篇白皮书文章

[Toward Next-Generation Artificial Intelligence: Catalyzing the NeuroAI Revolution​arxiv.org/abs/2210.08340](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2210.08340)

文章的观点非常简单，摘要只有两句话：**Neuroscience has long been an important driver of progress in artificial intelligence (AI). We propose that to accelerate progress in AI, we must invest in fundamental research in NeuroAI.**

概括起来就是：神经科学+人工智能非常有前途，政府请打钱。

中文的公众号文章可以参考 [@AI科技评论](https://www.zhihu.com/people/2e1c451acaffe7a329f511c189ba89e0)的这篇

[AI科技评论：Bengio、LeCun 等人联名发布 NeuroAI 白皮书：智能的本质是感觉运动能力，AI 迎来具身图灵测试大挑战8 赞同 · 0 评论文章![](https://pic3.zhimg.com/v2-fc9fb6e6a21dc99bee0c48674b27bb8f_180x120.jpg)
](https://zhuanlan.zhihu.com/p/575911093)

  

。一般这种事情都是大佬们利用自己的声音，对领域的发展提出一个方向，向政府建言争取更多资源支持，对自己江湖地位和声望有好处，热度炒起来了，相关从业的小虾米也开心。

所以文章发表之后，作者之一，宾夕法尼亚大学教授的Konrad Kording就开开心心的发了条tweet推广这篇文章，并呼吁了 一些东西。前两天还相安无事儿，大家其乐融融。

没想到两天后，可能是周末比较清闲，来自DeepMind的**[David Pfau](https://link.zhihu.com/?target=http%3A//davidpfau.com/)**对着Kording的这篇tweet开喷了：

> 神经科学从来都没推动过人工智能，你们白皮书中还说continue to drive AI progress  
>   
> 你们真的认为发明Transfor[mers](https://www.zhihu.com/search?q=mers&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2728729351%7D) / ADAM的人看过一篇神经科学论文吗？你们就假装在为人工智能做贡献吧。要点脸吧 "**it's embarrasing**"(原文）

![](https://pic4.zhimg.com/v2-5d124cad31733700d744a8ec07fcb1d1_b.jpg)

这样的回复立马就炸雷了，引起了后面很多人的“参战”。

这里简单提一下这位Pfau，他其实是正儿八经的神经科学博士，毕业于**哥伦比亚大学的神经生物学专业**，附属于[Center for Theoretical Neuroscience](https://link.zhihu.com/?target=https%3A//ctn.zuckermaninstitute.columbia.edu/) （CTN）。跟我（博后期间）同一个导师，只不过我们时间上没有交集，并没有任何交流。

说这个背景，主要是让大家不要觉得Pfau是不懂任何神经科学，盲目自大，他是受过完整神经科学训练的。并且在CTN里边有Larry Abbott和Ken Miller等计算神经科学大佬，毕业生中走出了很多在人工智能领域的佼佼者，如David Sussillo (下文会出现）。Pfau对于这神经科学和人工智能两个领域都不陌生。

诸神参战
----

### David Sussillo

Pfau的评论一处，上文我们所提到的David Sussillo就出来说话了

> 过去几年，我在Google Brain跟Transformer的主要贡献人交往很多。我虽然不能冒昧地推定到底是什么启发了他发明transformer，但是他对神经科学是发自内心的感兴趣，问了很多神经科学的问题。  
>   
> 格局打开，深度学习/人工智能的科学原理早晚都需要被解决，我押宝计算/理论/神经科学领域的人。

![](https://pic4.zhimg.com/v2-b380205c6474ec2e695955ca80dbf1b5_b.jpg)

对此， Pfau也直接回复

> 人工智能的人对神经科学感兴趣没问题，这和神经科学推动AI进展是两码子事儿。  
>   
> Sussillo你自己在运动控制方面的神经科学工作非常有影响力，你能举出来任何这些工作在机器人领域的应用吗？

![](https://pic3.zhimg.com/v2-3ec0d00c45cccf4bfed872cbbf7d51e9_b.jpg)

对此，Sussillo倒是也坦诚

> 没，我在运动控制领域的工作在AI中没啥影响。我曾经试图将动力学系统方面的思路引入到深度学习的理解中，但是没啥大成果。这个领域不太鼓励进展缓慢的增量式工作。

![](https://pic2.zhimg.com/v2-efab7a04f010371497c09e0a73c406bf_b.jpg)

Kording一看Sussillo这么坦诚，被Pfau将了一军，赶紧出来发言助攻。

> [Emo Todorov](https://link.zhihu.com/?target=https%3A//homes.cs.washington.edu/~todorov/index.php)在运动控制方面的工作在人工智能领域的应用比比皆是。

![](https://pic3.zhimg.com/v2-34f1dff85e438037b689375bf9ad2cf0_b.jpg)

Pfau对此也毫不客气

> 得了吧，Todorov的主要身份就不是神经科学家。他是做过一些神经科学的工作，但是我认为人工智能领域所认可他的工作主要来自控制理论。

Kording也立马回复

> 他的控制理论一开始就是为了解释神经科学的运动行为的。

**至此，我们可以看出来分歧已经出现在：到底什么才能被定义为神经科学？为了解释神经系统功能所用到的控制理论、数学、物理、统计、计算机手段是否还能被认为是神经科学**？我的个人观点在后边说，大家继续看戏。

Sussillo这时候估计也是觉得这样辩论就没意思了，赶紧总结了自己的观点，给双方台阶下，准备退出

> 算了，如果你就是不爽Kording所说的“神经科学继续推动人工智能”的话，那就算是吧。  
>   
> 过去的十年，深度学习领域到处都在跑马圈地，偶尔有一系列真正令人惊叹的想法出现。我认为神经科学在这个过程中没有贡献。 我承认这一点，并且同意目前神经科学对人工智能的贡献远不如后者对前者的大。  
>   
> 但我不爽的是，你说“神经科学家宣称对人工智能有贡献”就是embassing的。你说的太过了。  
>   
> 人工智能的历史吸纳了很多不同领域的人到一起。就拿NIPS为例，神经科学也依然在这个会议中有一席之地。

![](https://pic4.zhimg.com/v2-6b47718e9098753778458ba4a229a5c2_b.jpg)

这里我简单插入一点内容：近些年在中文互联网上， NIPS的文章讨论已经几乎全部是计算机领域的了，但实际上它是有一部分留给神经科学的。有趣的是，我在wiki上看NIPS的介绍，说的还是NIPS is a **machine learning and computational neuroscience** conference, 以及说NIPS was designed as a meeting for researchers **exploring biological and artificial neural networks**，但是NIPS的官网的mission statement说的是foster the exchange of research advances in **Artificial Intelligence and Machine Learning。** 

这可真是从“小甜甜”到“牛夫人”的转变啊。NIPS都如此，这也难怪现在人工智能领域的新生代不屑于了解神经科学。而在上个世纪，最早那一批做人工智能的对脑智能还是非常感兴趣的。

![](https://pic1.zhimg.com/v2-bda2c9a4f93f250fa667bb4ff51f4dd5_b.jpg)

最后Sussillo给Pfau推荐了几篇做人工智能可以看看的神经科学文章，然后退出了争论。

> [https://www.biorxiv.org/content/10.1101/2022.08.15.503870v1.abstract](https://link.zhihu.com/?target=https%3A//www.biorxiv.org/content/10.1101/2022.08.15.503870v1.abstract)  
>   
> [How recurrent networks implement contextual processing in sentiment analysis](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2004.08013)  
>   
> [Reverse engineering learned optimizers reveals known and novel mechanisms](https://link.zhihu.com/?target=https%3A//proceedings.neurips.cc/paper/2021/hash/a57ecd54d4df7d999bd9c5e3b973ec75-Abstract.html)

![](https://pic3.zhimg.com/v2-ab68c5e85b8a531b4e46f75cdda3fa8b_b.jpg)

### Ken Miller

[Ken Miller](https://link.zhihu.com/?target=http%3A//www.columbia.edu/cu/neurotheory/Ken/)是Pfau所毕业的哥大理论神经科学中心的大佬，他肯定是认识Pfau。Ken是一个非常受人尊敬的理论神经科学家，致力于研究大脑皮层环路的计算规则，是研究脑智能的一座山，现在突然听到Pfau这番言论，肯定是很不爽的。于是连发了三条评论就离开了，而Pfau也没有直接回复Ken，不知道是否是出于一种尊重，或者是他觉得Ken这种说法太泛了。

> Pfau你小子，真觉得一个从没听说过神经元和突触相关概念的人会想到使用人工神经网络来实现人工智能吗？  
>   
> 你忘了1990-2012年的神经网络寒冬了吗？ 一帮受脑智能启发的头铁的牛人给神经网络续了命，虽然那段时间整个人工智能/机器学习领域都抛弃了他们。  
>   
> 人类擅长抽象推理模式，但这是不会带领我们想到通过神经网络/卷积网络来实现智能的。而那帮头铁的老家伙们就是坚信“大脑可以做到，那人工神经网络也行”，靠着这个信念坚持走过了人工神经网络的黑暗时期。  
>   
> 现在你居然在问“神经科学为人工智能做了啥”？真拿神经科学是牛夫人了？  
>   
> 上一次神经科学对人工智能的贡献在于认识到大脑是通过层级间的神经元和突触连接实现信息处理这一抽象的概念，**我认为下一波重大贡献将来自于我们真正理解大脑如何完成计算的**。目前我们还远没到这个地步。

![](https://pic1.zhimg.com/v2-d0ffdaf3d10960424331b05dc12519b9_b.jpg)

### Yann Lecun

大佬出马了，直接就一句"You are wrong"甩到Pfau老兄脸上了

> 你错了 。神经科学极大并且直接启发了我和Hinton  
>   
> 另外神经网络通过调节突触权重来实现学习这一整套想法确定无疑来自神经科学。

![](https://pic4.zhimg.com/v2-792b95924eda07437d9b3fc379a3b1e9_b.jpg)

当然了，遇到和大佬对线的机会，Pfau也不会轻易放弃，赶紧说

> 从一些经典工作获得一些概念上的启发和直接从最近研究中获得启发是不同的。你有从Neuron或者Cell杂志上的最新文章受到任何启发，并作出新的工作吗？如果有的话，我没注意到你文章中有这些体现。

这里我觉得Pfau有点太偏执了，神经科学的第一任务是理解大脑的工作原理，而不是为了整天为人工智能提供新的启发。你这对比就是拿classic和latest research对比。LeCun估计也是觉得这样说就没意思了，就直接不回复了。

此外，Pfau又补了一句

> Mike Jordan说当年的PDP group都非常讨厌backprop，因为它在生物学上不现实。  
>   
> 直到你们这波人不管生物学意义后，才变得流行了。大佬，你当年因为一些神经学家过分追求生物合理性而被刁难的日子，你都忘了吗？

![](https://pic2.zhimg.com/v2-339baf63e596dfae634c4a58d755eb60_b.jpg)

### Tony Zador

[Tony Zador](https://zadorlab.labsites.cshl.edu/) 是冷泉港实验室的一个大佬，他也是前文提到的白皮书作者之一。他看到Pfau对LeCun的回复后，就开喷了

> 你丫这么说就类似于问一个物理学家是否看过哪些最近发表的数学论文，并启发自己完成一些新的工作？  
>   
> “嘿，费曼，你最近看过Acta Mathematica上的论文吗，有没有直接推动你工作的？如果没有的话，那物理学家不需要学数学了”

![](https://pic1.zhimg.com/v2-3890ac0de209560bbcd624815bdb1ea4_b.jpg)

Pfau也挺善战，立马就说

> 你要说费曼，我就不困了。在《别逗了，费曼先生》一书中，他说他觉得纯数太繁琐并且不相关。他有问题就直接去找数学家问了

不过我觉得这回答的是个啥？Zador也作出了回应（如下，我就不翻译了）。

![](https://pic1.zhimg.com/v2-3f148b8bb71b54e08709294f30de56d2_b.jpg)

在另外一条线中，Zador也参与了一点争论。起因是有人说Hinton在报告中提到Dropout的发现是因为他注意到神经元的活动是随机的。我查了Hinton的那篇文章，没有提任何neuroscience的事情，也没有引用。对文章撰写来说，而也是很正常的，文章最后的组织和表述不用完全反映真实的心路历程。

![](https://pica.zhimg.com/v2-c20eb44c4590575022bf0471bc94e4bb_b.jpg)

然后Pfau估计那天也是杀疯了，上来就说

> 我怀疑Hinton从来没有看过任何一篇神经科学的论文。被一些high-level的直觉启发，跟被实际的神经科学研究启发是两回事儿。

于是Zador就说

> 你是不是指望神经科学文章中的某个图片结论直接被应用到某些 人工智能算法中？如果这是你期待的话，那肯定不是这样的。  
>   
> 事实上，我们从神经科学获得一些启发，然后把那些重要的想法移植到AI中并进而改善它。

Pfau也直接回复

> 实际上你说的这种形式也不常见。有些人从神经科学中寻找启发，其他人完全无视神经科学也没啥，依然可以作出领域内的重大贡献。

![](https://pic4.zhimg.com/v2-14d255df216629499353f836ddc8fd75_b.jpg)

这里我是不认同Pfau关于Hinton不看神经科学论文这一说法的。**[Terry Sejnowski](https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Terry_Sejnowski)**在_The Deep Learning Revolution_一书中花了很多篇幅写自己和Hinton的关系。人工智能领域的新生代可能不了解Terry，他是美国的National Academy of Sciences， American Academy of Arts and Sciences， American Association Advancement of Science, National Academy of Engineering, National Academy of Medicine, National Academy of Inventors 多院的院士（学术称号buff加满的存在），计算神经科学领域的先驱，高山仰止那种角色。他和Hinton早期有很多关于神经网络方面的合作。后来两个人的研究方向分别走向了两个领域：一个注重利用神经网络实现人工智能，另外一个专注于理解大脑工作原理。我相信两位大佬是希望这两个领域是可以互相促进的。在Terry的书中，他写了这么一段话

> Every few years, I get a call from Geoffrey that begins with **"I figured out how the brain works."** Each time, he tells me about a clever new scheme for improving neural network models. It has taken many such schemes and refinements for deep learning in multilayered neural networks to achieve a level of performance comparable to humans in recognizing speech on cell phones and objects in photos.

从这里我们看出，Hinton每次对他网络的修改，总是想和大脑对应上，寻求二者原理上的共性。所以我觉得这里Pfau是太武断了。

### Gary Marcus

[Gary Marcus](https://link.zhihu.com/?target=http%3A//garymarcus.com/) 曾经是NYU心理系最年轻的荣誉退休教授。他对Pfau所说的神经学家过度关心生物合理性也回应了一下

> 是的，对神经网络生物合理性的要求过度了。但我同意LeCun，Pfau这小子太口无遮拦了，缺乏对历史背景的了解。

![](https://pic3.zhimg.com/v2-cdb4451d16cbb0661cbebaca996bdad5_b.jpg)

Pfau老哥怎能服气，立马就杠上了

> 你瞎说，我当然知道历史背景。我只是认为几个教科书中关于抽象的启发完全不等于是主要推动力。

Marcus也很老道，不跟他硬杠

> 好吧，你这么说也没毛病。那咱们就说“60年代有一些是有实际贡献，1970年以后就没啥大的推动了”

![](https://pic3.zhimg.com/v2-6ff265c037fec9efa88a066e74dffe53_b.jpg)

最后这个Markus还是非常善意的提供了一些神经科学中可供AI领域参考的概念，然后消失了，深藏功与名。

![](https://pic3.zhimg.com/v2-4ac975d4f03559cf36d51737ca9ef3e1_b.jpg)

### Eran Mukamel

**[Eran Mukamel](https://link.zhihu.com/?target=https%3A//brainome.ucsd.edu/)**是UCSD认知神经科学系的一个教授，湿实验比较多。我知道他是因为我之前一些工作经常会拿他的一个自动分析算法对比。Mukamel和Pfau俩家简单斗了一下嘴，没啥特别有趣的争论。大家自己看截图吧。

![](https://pica.zhimg.com/v2-cff2f66e789cda3d7bd0c1ad3c3a05ae_b.jpg)

鸣金收兵
----

后来双方都很累了，Pfau也没想到自己直接点燃了一个火药桶，一个周末就这么荒废了，全程与各位对战，也承认自己处境很尴尬，不过他是坚决不认输。

![](https://pica.zhimg.com/v2-fbeed4639e784b970109a74710cfa2bb_b.jpg)

争论中的另一个主角也不开心地发了个佛系的tweet。

![](https://pic2.zhimg.com/v2-1cb9093659ab33dddb8c969dcd558cba_b.jpg)

  

个人观点
----

我是战火结束了才跑去吃瓜的，吃得还是挺开心。我很欣赏David Pfau这样的人抛出来这个话题，并且面对各个大佬都从容应对，虽然我不是很认同他的某些说法。但是我觉得Nicole Rust下边的这条评论基本表达了我的感受。

![](https://pic2.zhimg.com/v2-787de9dc27420dc7cad1e96da447a4a5_b.jpg)

这条twitter下的争论还有很多，我原本想着一会儿工作就整理完了，结果我严重低估了工作量。剩下的我就暂时先不整理了。如果感兴趣的话，可以去围观另外一条主线，来自Harvard的教授Sam Gershman也开辟了一个战场，下面依然有Tony Zador大神的火力输出。[https://twitter.com/gershbrain/status/1583785652516098049](https://link.zhihu.com/?target=https%3A//twitter.com/gershbrain/status/1583785652516098049)

![](https://pic1.zhimg.com/v2-2399422a37eabfa343871d2a90948d8c_b.jpg)

另外大家不要觉得都是喷Pfau的，其实也有很多人是支持Pfau，并且认为“根本不用关心neuroscience进展的”，以及“neuroscience在这一波deep learning浪潮中啥也没干”，对此我觉得也没啥不妥。

早在2015年时候，就有一个知乎讨论，有个回答也是说“不觉得做人工智能一定要先学点生物”，对此我是认同的。神经科学不需要所有人都学习。

  

最后发表一下我在吃瓜过程中的一些看法，欢迎讨论。

### 人工智能有很多途径，NeuroAI只是一个选择

我觉得这里没必要厚此薄彼。有人觉得神经科学 ->人工智能是一条不错的道路，有人觉得完全不需要神经科学也一样可以做的很好。那没问题，各走各的道，谁也别想着干涉谁。神经科学对于过去十年的所谓的“人工智能”发展没啥大的贡献，这是事实；如果有，那也是早年的先驱概念性启发，跟当代的神经科学没啥大的关系，没必要去邀功。

但是你要说未来是否有贡献，那我觉得是会的。有人觉得不会，那也没关系，就像1990-2012年间那样，大部分人觉得人工神经网络不值得研究一样。

另外Pfau这种“神经科学对人工智能没有贡献的说法”，我觉得有一个很大的问题：**谁来定义人工智能？**有人从工程角度研究，有人从脑智能启发。后者目前慢，但是就直接否定了其存在，从人工智能领域踢出去是否合适？我们是否换个角度看，研究脑科学就是研究人工智能？

总结起来就是，做神经科学的不要随意邀功，免得一种“我祖上阔过”的印象；做非神经相关的AI研究者，也不要随意贬低其它领域的研究。

### 属于脑科学的“空气动力学”还未到来

大家经常会拿鸟和飞机来类比脑科学和人工智能。白皮书中也对此有一个回应，主要是强调这个类比不合理。造飞机的目的不是为了像鸟，但是人工智能的一个目的是为了像人（此处有争议，有些觉得人工智能不需要像人，但是要超越人类的水平）。

我个人觉得除了白皮书中所说的，还有一条就是属于脑科学的空气动力学还未到来。人们从研究鸟发现了空气动力学，然后就可以抛开鸟类，专注空气动力学就可以造出来更大更快的飞机。但是对于脑智能来说，我们还没有发现可以解释其计算原理的理论，在类脑智能领域尚没有可以脱离大脑可以独立发展的“空气动力学”。所以我觉得Ken Miller的评论是中肯的。

![](https://pic4.zhimg.com/v2-749423efe5ca3ec71696fb2f82a6996d_b.jpg)

### 神经科学如何界定？

Pfau在争论中有个观点其实是具有迷惑性的。他只承认实验得到的神经科学结论，而拒绝认为来自控制理论、数学、认知科学的研究属于神经科学。

如果持有这个观点，那么他很难在辩论中失败。因为所有被人工智能所吸收的理论都会被他说成是另外一个学科，而非神经学科。

但实际上神经科学的定义非常模糊，我迄今都没有严格区分neuroscience, neurology, neurobiology, coginitive neuroscience等细分方向。我觉得凡是**以神经系统为研究对象，为此开发的理论、方法以及实验发现都属于神经科学。** 

毕竟现代神经网络的先驱们很多都是数学、物理方向，大多都是怀着对人类智能的兴趣而进行相关的探索。他们有的走向人工神经网络，有的走向生物脑的原理解析。

对于**历史上的大师而言，他们眼中没有细分的专业，而只有人类未解之谜。如果需要，他们可以自己创造一个专业**。

  

### 目前神经科学还处于初级阶段，但已经是最好的时代

神经科学是一个非常吸引人的学科，里边的未解之谜实在太多。有很多人在年轻时候都试图去研究它，进了一些神经科学的博士项目。

但真正进入了之后，才发现我们的研究手段如此初级，离自己想象差距好大，感叹在有生之年估计是无法解答自己的疑惑。

比如Jeff Hawkins进入了UC Berkeley的神经科学PhD项目，读了一段时间觉得有点希望渺茫，于是就辍学去了硅谷，创建了Palm Computing公司，赚了大钱后，在UC Berkeley赞助了一个Redwood Center for Theoretical Neuroscience，继续赞助一帮大佬进行神经科学研究。

### 对人工智能的启发可以有很多种

神经元和突触连接这些概念对于最早期的人工神经网络来说，我认为是肯定很关键的。**这是从其它实体中很难获得的一种启发，其难度应该可以类比从我们日常生活想象[量子力学](https://www.zhihu.com/search?q=%E9%87%8F%E5%AD%90%E5%8A%9B%E5%AD%A6&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2728729351%7D)一样**。这要得益与人类历史上一些伟大的实验科学家和一群对智能原理孜孜不倦思索的理论家。

但是具体到某些算法，可获得的启发就可以来自方方面面了。Hinton在[reddit上提了关于发明dropout的一些历程](https://link.zhihu.com/?target=https%3A//www.reddit.com/r/MachineLearning/comments/4w6tsv/comment/d6dgyse/%3Futm_source%3Dshare%26utm_medium%3Dweb2x%26context%3D3)。其中提到了2004年时候，他觉得大脑执行一个任务只用部分神经元激活即可，因此有了dropout的想法。后来他又从银行工作人员轮流上班而不影响客户办理业务。这两种事情都促使他有了最初的 dropout想法。

![](https://pic3.zhimg.com/v2-ba798bd6ae2df4f4f23c6c37d3260367_b.jpg)

### 未来的NeuronAI政府资助

与此次争论无关的几条回复来自美国的[IARPA](https://link.zhihu.com/?target=https%3A//www.iarpa.gov/)的一个负责人David Markowitz，他是我之前参与的一个MICrONS项目的政府方面的管理者。MICrONS算是美国政府投入非常大的一个NeuroAI项目。David从经费管理者角度上回应了这篇文章，总体上是支持这一领域，但是科学家们需要拿出更多成果，给经费分配者以信心。

![](https://pic2.zhimg.com/v2-ddc82982b30bbeccc37b00fb973b327d_b.jpg)

![](https://pic3.zhimg.com/v2-3f574efb7e199e3c6116c0f6c3835b62_b.jpg)
